{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_hello_world.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1hDtn3PRnl7yigkX04rAuAu_CFpn5FnXS",
      "authorship_tag": "ABX9TyPbFtIdRsPV8sXBJhsvkhV9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wenxuan0923/My-notes/blob/master/DL_hello_world.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uh4o58SPXMAE",
        "colab_type": "text"
      },
      "source": [
        "## The 'Hello World' of Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmzp4J8DcxIP",
        "colab_type": "text"
      },
      "source": [
        "### A toy dataset to get us started\n",
        "\n",
        "A regression problem with 3D feature space and 50 data points."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ex7v_PJtXW_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqslCjqlalgc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = np.random.random((50, 3))\n",
        "target = 2*np.sum(data, axis=1) - 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYu9OVQJmiM3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7ff34398-2788-4ee0-da49-92206544f6bb"
      },
      "source": [
        "display(data[0])\n",
        "display(target[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([0.97865752, 0.89013968, 0.0571576 ])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "2.8519095984378233"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZ2QmnOSh4QU",
        "colab_type": "text"
      },
      "source": [
        "* (50, 3) corresponds to (samples, features)\n",
        "> We created 50 samples here, each of them is represented by 3 features<br>\n",
        "> For Example: $[0.36117813, 0.49405359, 0.5331897 ]$ \n",
        "\n",
        "* target is the target variable we want to predict, it is defined by a linear function here (the real relationship):\n",
        "> For the sample above, its corresponding target value is $2*(0.36117813 + 0.49405359 + 0.5331897) - 1 = 1.77684$\n",
        "\n",
        "Imagin you are given a new sample $[0.1, 0.2, 0.3]$, the ideal prediction result should be $2*(0.1 + 0.2 + 0.3) - 1 = 0.2$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtEwmL-OcUwT",
        "colab_type": "text"
      },
      "source": [
        "### Build a deep learning model using Keras\n",
        "A deep learning models is used to learn the relationship between input data and target variable.\n",
        "* The core data structure of Keras is a **model**, a way to organize layers\n",
        "* The simplest type of model is the **sequential model**, a linear stack of layers\n",
        "* You can create a Sequential model by passing a list of **layer instances** to the constructor\n",
        "\n",
        "**What is heppening in these Layers?**\n",
        "\n",
        "Layers extract **representations** out of the data fed into them through data transformation\n",
        "\n",
        "> You can consider it as a **data distillation** process:\n",
        "> * Some data goes in and comes out in a more informative form <br>\n",
        "> * Some unuseful information will be dropped during this process\n",
        "\n",
        "For those who is interested in the math under the hood, I will explain in <a href='#'> this </a> tutorial. For now, let's build our first DL model using Keras!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAMj1NBoZHr3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "8f06f0ab-45eb-4ba9-a23d-8b5b1097972b"
      },
      "source": [
        "import keras\n",
        "\n",
        "# A neural network with 1 hidden layer with 3 units\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Dense(units=3, input_dim=3))\n",
        "model.add(keras.layers.Dense(units=1))\n",
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 4         \n",
            "=================================================================\n",
            "Total params: 16\n",
            "Trainable params: 16\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9doo_sl6fz2",
        "colab_type": "text"
      },
      "source": [
        "**The structure of a neural network with 1 hidden layer with 3 units:**\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src = 'https://drive.google.com/uc?id=16Wd_swdEhLn4bdT1JgJ4BskJp_G_-s-1",
        "width=\"380\" height=\"340\" style=\"vertical-align:middle\"/>\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glHsGp9O7aFi",
        "colab_type": "text"
      },
      "source": [
        "Now you have defined the structure of the deep learning model. Before training it you need to configure the learning process, which is done via the **compile** method. It receives three arguments: \n",
        "\n",
        "1. A **loss function** is used to measure the performance of the model on the training data. Model training is a process of finding the best combination of parameters which will lead to the smallest loss\n",
        "2. An **optimizer** will determine how to update the parameters to further minimize the loss according to the current loss score\n",
        "3. A list of **metrics** for you to monitor the performance on the training, validation and testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXGZDFRvV_pR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='sgd', \n",
        "              loss='mean_squared_error',\n",
        "              metrics=['mse'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2MUXC4pf-Mu",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "**Relationship between the network, layers, loss function, and optimizer**\n",
        "<p align=\"center\">\n",
        "<img src = 'https://drive.google.com/uc?id=1TXMLZ0bTdI9uBDzAvYHKoQ5FOpQsP71Y' width=\"480\" height=\"450\" style=\"vertical-align:middle\"/>\n",
        "</p>\n",
        "Flow Chart from: 'Deep Learning with Python' by Fran√ßois Chollet.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OErKoKI6wHmQ",
        "colab_type": "text"
      },
      "source": [
        "You can now iterate on your training data in batches and epochs.\n",
        "* **Batch** specifies the number of training data used to calculate the loss signal and update the parameters\n",
        "* **Epoch** specifies the number of iterations the model iterate through the whole training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6jm2WwxwGkW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7f20dd5c-cb6a-4a95-868d-5be0a481e80f"
      },
      "source": [
        "# Train the model for 50 epochs in mini-batch of 16 samples\n",
        "model.fit(data, target, batch_size=16, epochs=50)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "50/50 [==============================] - 0s 381us/step - loss: 9.4546e-05 - mse: 9.4546e-05\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 0s 129us/step - loss: 9.1616e-05 - mse: 9.1616e-05\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 0s 171us/step - loss: 8.7045e-05 - mse: 8.7045e-05\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 0s 139us/step - loss: 8.4108e-05 - mse: 8.4108e-05\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 0s 129us/step - loss: 7.9272e-05 - mse: 7.9272e-05\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 0s 139us/step - loss: 7.6390e-05 - mse: 7.6390e-05\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 0s 126us/step - loss: 7.2777e-05 - mse: 7.2777e-05\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 0s 121us/step - loss: 6.8834e-05 - mse: 6.8834e-05\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 0s 123us/step - loss: 6.5537e-05 - mse: 6.5537e-05\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 0s 177us/step - loss: 6.3477e-05 - mse: 6.3477e-05\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 0s 134us/step - loss: 6.1283e-05 - mse: 6.1283e-05\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 0s 146us/step - loss: 5.7204e-05 - mse: 5.7204e-05\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 0s 151us/step - loss: 5.4559e-05 - mse: 5.4558e-05\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 0s 129us/step - loss: 5.2513e-05 - mse: 5.2513e-05\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 0s 134us/step - loss: 5.0394e-05 - mse: 5.0394e-05\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 0s 139us/step - loss: 4.8888e-05 - mse: 4.8888e-05\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 0s 104us/step - loss: 4.5484e-05 - mse: 4.5484e-05\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 0s 112us/step - loss: 4.4304e-05 - mse: 4.4304e-05\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 0s 126us/step - loss: 4.2097e-05 - mse: 4.2097e-05\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 0s 124us/step - loss: 4.0267e-05 - mse: 4.0267e-05\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 0s 124us/step - loss: 3.8926e-05 - mse: 3.8926e-05\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 0s 138us/step - loss: 3.7635e-05 - mse: 3.7635e-05\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 0s 158us/step - loss: 3.5914e-05 - mse: 3.5914e-05\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 0s 182us/step - loss: 3.5009e-05 - mse: 3.5009e-05\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 0s 198us/step - loss: 3.2587e-05 - mse: 3.2587e-05\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 0s 204us/step - loss: 3.1845e-05 - mse: 3.1845e-05\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 0s 194us/step - loss: 2.9469e-05 - mse: 2.9469e-05\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 0s 156us/step - loss: 2.8335e-05 - mse: 2.8335e-05\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 0s 188us/step - loss: 2.7546e-05 - mse: 2.7546e-05\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 0s 145us/step - loss: 2.7949e-05 - mse: 2.7949e-05\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 0s 118us/step - loss: 2.5348e-05 - mse: 2.5348e-05\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 0s 148us/step - loss: 2.3568e-05 - mse: 2.3568e-05\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 0s 162us/step - loss: 2.3326e-05 - mse: 2.3326e-05\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 0s 119us/step - loss: 2.1484e-05 - mse: 2.1484e-05\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 0s 161us/step - loss: 2.0506e-05 - mse: 2.0506e-05\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 0s 143us/step - loss: 1.9537e-05 - mse: 1.9537e-05\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 0s 119us/step - loss: 1.9273e-05 - mse: 1.9273e-05\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 0s 137us/step - loss: 1.8934e-05 - mse: 1.8934e-05\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 0s 146us/step - loss: 1.6944e-05 - mse: 1.6944e-05\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 0s 128us/step - loss: 1.6115e-05 - mse: 1.6115e-05\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 0s 146us/step - loss: 1.5352e-05 - mse: 1.5352e-05\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 0s 182us/step - loss: 1.4493e-05 - mse: 1.4493e-05\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 0s 161us/step - loss: 1.4026e-05 - mse: 1.4026e-05\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 0s 150us/step - loss: 1.3793e-05 - mse: 1.3793e-05\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 0s 156us/step - loss: 1.2517e-05 - mse: 1.2517e-05\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 0s 160us/step - loss: 1.1993e-05 - mse: 1.1993e-05\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 0s 233us/step - loss: 1.1507e-05 - mse: 1.1507e-05\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 0s 202us/step - loss: 1.1061e-05 - mse: 1.1061e-05\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 0s 124us/step - loss: 1.0615e-05 - mse: 1.0615e-05\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 0s 142us/step - loss: 1.0057e-05 - mse: 1.0057e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fd3e2ec2f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6v7-Oy1bwQNx",
        "colab_type": "text"
      },
      "source": [
        "Once the model is trained, you can make predictions on new data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WoRewo3wPVq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b454f23b-be3b-4347-9822-7fe5dcf75937"
      },
      "source": [
        "model.predict(np.array([[0.1, 0.2, 0.3]]))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.20596062]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pL-8ceRZ5lZG",
        "colab_type": "text"
      },
      "source": [
        "Yay! It's very close to the true value! Now we have finished building our first DL model using Keras. "
      ]
    }
  ]
}
