{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CountVectorizer_TfidfVectorizer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNQh08UHgC27kmMm1yuzJzU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wenxuan0923/My-notes/blob/master/CountVectorizer_TfidfVectorizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ss49wvpKRkIH",
        "colab_type": "text"
      },
      "source": [
        "# Text Feature Extration\n",
        "## CountVectorizer & TfidfVectorizer\n",
        "\n",
        "**Vectorization** is the general process of turning a collection of text documents into numerical feature vectors. This specific strategy (tokenization, counting and normalization) is called the **Bag of Words** or \"Bag of n-grams\" representation. Documents are described by word occurrences while completely ignoring the relative position information of the words in the document. \n",
        "\n",
        "This note will cover the most popular feature extraction techniques for text data: **CountVectorizer** and **TfidfVectorizer** from `sklearn.feature_extraction.text` class using a toy document set.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjaNslAsT2lz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import (CountVectorizer, \n",
        "                                             TfidfVectorizer,\n",
        "                                             TfidfTransformer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STbUlOxZR1di",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = [\"The greatest thing of life is love.\",\n",
        "          \"Love is great, it's great to be loved.\",\n",
        "          \"Is love the greatest thing?\",\n",
        "          \"I love lasagna for 1000 times\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBpuUqa0d_rI",
        "colab_type": "text"
      },
      "source": [
        "## CountVectorizer\n",
        "\n",
        "**CountVectorizer** converts a collection of text documents to a matrix of token counts: **the occurrences of tokens in each document**.\n",
        "\n",
        "This implementation produces a sparse representation of the counts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wEN7a2-RPsJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "06bf4a59-14ad-4125-98a3-2b144279f2d2"
      },
      "source": [
        "vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 1))\n",
        "vectorized = vectorizer.fit_transform(corpus)\n",
        "pd.DataFrame(vectorized.toarray(), \n",
        "            index=['sentence '+str(i) for i in range(1, 1+len(corpus))],\n",
        "            columns=vectorizer.get_feature_names())"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1000</th>\n",
              "      <th>be</th>\n",
              "      <th>for</th>\n",
              "      <th>great</th>\n",
              "      <th>greatest</th>\n",
              "      <th>is</th>\n",
              "      <th>it</th>\n",
              "      <th>lasagna</th>\n",
              "      <th>life</th>\n",
              "      <th>love</th>\n",
              "      <th>loved</th>\n",
              "      <th>of</th>\n",
              "      <th>the</th>\n",
              "      <th>thing</th>\n",
              "      <th>times</th>\n",
              "      <th>to</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>sentence 1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentence 2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentence 3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentence 4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            1000  be  for  great  greatest  ...  of  the  thing  times  to\n",
              "sentence 1     0   0    0      0         1  ...   1    1      1      0   0\n",
              "sentence 2     0   1    0      2         0  ...   0    0      0      0   1\n",
              "sentence 3     0   0    0      0         1  ...   0    1      1      0   0\n",
              "sentence 4     1   0    1      0         0  ...   0    0      0      1   0\n",
              "\n",
              "[4 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Myf72cNrWDKi",
        "colab_type": "text"
      },
      "source": [
        "Note that for each sentence in the corpus, the position of the tokens (words in our case) is completly ignored. When constructing this bag-of-words representation, the default configuration tokenizes the string by extracting words of at least 2 alphanumeric characters (punctuation is completely ignored and always treated as a token separator). \n",
        "\n",
        "### Consider only certain pattern\n",
        "\n",
        "We can also specify the desired pattern for our token using `token_pattern` argument.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPhIvLI5R1f3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "955b4780-ea4d-4c4e-ba28-4e20c8a7c239"
      },
      "source": [
        "vectorizer = CountVectorizer(analyzer='word', \n",
        "                              token_pattern=r'\\b[a-zA-Z]{3,}\\b',  # Only alphabet, contains at least 3 letters\n",
        "                              ngram_range=(1, 1))\n",
        "vectorized = vectorizer.fit_transform(corpus)\n",
        "pd.DataFrame(vectorized.toarray(), \n",
        "             index=['sentence '+str(i) for i in range(1, 1+len(corpus))],\n",
        "             columns=vectorizer.get_feature_names())"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>for</th>\n",
              "      <th>great</th>\n",
              "      <th>greatest</th>\n",
              "      <th>lasagna</th>\n",
              "      <th>life</th>\n",
              "      <th>love</th>\n",
              "      <th>loved</th>\n",
              "      <th>the</th>\n",
              "      <th>thing</th>\n",
              "      <th>times</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>sentence 1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentence 2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentence 3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentence 4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            for  great  greatest  lasagna  life  love  loved  the  thing  times\n",
              "sentence 1    0      0         1        0     1     1      0    1      1      0\n",
              "sentence 2    0      2         0        0     0     1      1    0      0      0\n",
              "sentence 3    0      0         1        0     0     1      0    1      1      0\n",
              "sentence 4    1      0         0        1     0     1      0    0      0      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFWPl3RoXKvU",
        "colab_type": "text"
      },
      "source": [
        "Note `1000`, `be`, `is`, `of` are removed from the original feature space.\n",
        "\n",
        "### Only consider unigrams/bigrams/... tokens\n",
        "\n",
        "- `ngram-range=(1, 1)`: unigram only\n",
        "- `ngram-range=(2, 2)`: bigrams only\n",
        "- `ngram-range=(1, 2)`: both unigrams and bigrams "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhGJlAU_R1iG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "10add379-c6c6-4cd9-a8df-42380f919932"
      },
      "source": [
        "vectorizer = CountVectorizer(analyzer='word', \n",
        "                              token_pattern=r'\\b[a-zA-Z]{3,}\\b',  # Only alphabet, contains at least 3 letters\n",
        "                              ngram_range=(2, 2))  # only bigrams\n",
        "vectorized = vectorizer.fit_transform(corpus)\n",
        "pd.DataFrame(vectorized.toarray(), \n",
        "             index=['sentence '+str(i) for i in range(1, 1+len(corpus))],\n",
        "             columns=vectorizer.get_feature_names())"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>for times</th>\n",
              "      <th>great great</th>\n",
              "      <th>great loved</th>\n",
              "      <th>greatest thing</th>\n",
              "      <th>lasagna for</th>\n",
              "      <th>life love</th>\n",
              "      <th>love great</th>\n",
              "      <th>love lasagna</th>\n",
              "      <th>love the</th>\n",
              "      <th>the greatest</th>\n",
              "      <th>thing life</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>sentence 1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentence 2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentence 3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentence 4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            for times  great great  ...  the greatest  thing life\n",
              "sentence 1          0            0  ...             1           1\n",
              "sentence 2          0            1  ...             0           0\n",
              "sentence 3          0            0  ...             1           0\n",
              "sentence 4          1            0  ...             0           0\n",
              "\n",
              "[4 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kjazd0bJZ-Lx",
        "colab_type": "text"
      },
      "source": [
        "### Only consider tokens occur certain times\n",
        "We can also make the vectorizer to ignore terms that have a **document frequency** stricly lower than a specified threshold by setting `min_df = threshold` or `max_df = threshold` for higher frequency terms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWCE-WPrZCEH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "9a19f640-6b3a-45d6-85f0-c98653facb9d"
      },
      "source": [
        "vectorizer = CountVectorizer(analyzer='word', \n",
        "                              token_pattern=r'\\b[a-zA-Z]{3,}\\b',  # Only alphabet, contains at least 3 letters\n",
        "                              ngram_range=(1, 2), # both unigrams and bigrams\n",
        "                              min_df = 2)  # occur at least twice\n",
        "vectorized = vectorizer.fit_transform(corpus)\n",
        "pd.DataFrame(vectorized.toarray(), \n",
        "             index=['sentence '+str(i) for i in range(1, 1+len(corpus))],\n",
        "             columns=vectorizer.get_feature_names())"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>greatest</th>\n",
              "      <th>greatest thing</th>\n",
              "      <th>love</th>\n",
              "      <th>the</th>\n",
              "      <th>the greatest</th>\n",
              "      <th>thing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>sentence 1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentence 2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentence 3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentence 4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            greatest  greatest thing  love  the  the greatest  thing\n",
              "sentence 1         1               1     1    1             1      1\n",
              "sentence 2         0               0     1    0             0      0\n",
              "sentence 3         1               1     1    1             1      1\n",
              "sentence 4         0               0     1    0             0      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wgd8BOUMbTbg",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## TF-IDF\n",
        "\n",
        "We can further transform a count matrix to a normalized **tf: term-frequency** or **tf-idf: term-frequency times inverse document-frequency** representation using **TfidfTransformer**. The formula that is used to compute the tf-idf for a **term t** of a **document d** in a document set is: <br><br>\n",
        "\n",
        "$$\\text{tf-idf}(t, d) = \\text{tf}(t, d) * log(\\frac{n}{df(t)+1})$$\n",
        "<br>\n",
        "\n",
        "when `smooth_idf=True`, which is also the default setting in sklearn.feature_extraction.text.TfidfTransformer \n",
        "\n",
        "> **tf(t, d)** is the number of times a term occurs in the given document. This is same with what we got from the CountVectorizer.\n",
        ">\n",
        "> **n** is the total number of documents in the document set\n",
        ">\n",
        "> **df(t)** is the number of documents in the document set that contain the term t\n",
        "\n",
        "The effect of adding 1 to the denominator of $\\text{idf}$ in the equation above is that terms with zero $\\text{idf}$, i.e., terms that occur in all documents in a training set, will not be entirely ignored. At the end, each row is normalized to have unit Euclidean norm (by dividing l2 norm of itself).\n",
        "\n",
        "The goal of using tf-idf instead of the raw frequencies of occurrence of a token in a given document is to **scale down the impact of tokens that occur very frequently** in a given corpus and that are hence empirically less informative than features that occur in a small fraction of the training corpus.\n",
        "\n",
        "## TfidfTransformer v.s. Tfidfvectorizer\n",
        "\n",
        "Both **TfidfTransformer** and **Tfidfvectorizer** modules can convert a collection of raw documents to a matrix of TF-IDF features.  However,\n",
        "\n",
        "- With **Tfidftransformer** you will systematically compute word counts using CountVectorizer and then compute the Inverse Document Frequency (IDF) values and only then compute the Tf-idf scores.\n",
        "\n",
        "- With **Tfidfvectorizer** on the contrary, you will do all three steps at once. Under the hood, it computes the word counts, IDF values, and Tf-idf scores all using the same dataset.\n",
        "\n",
        "The following two code snippets are actually the same thing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p05zmWSebs0m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "f7ef33a4-54ef-46b4-8c54-16199904c733"
      },
      "source": [
        "vectorizer = CountVectorizer(analyzer='word', \n",
        "                              token_pattern=r'\\b[a-zA-Z]{3,}\\b',  # Only alphabet, contains at least 3 letters\n",
        "                              ngram_range=(1, 1) # only unigrams\n",
        "                              )  \n",
        "count_vectorized = vectorizer.fit_transform(corpus)\n",
        "tfidf_transformer = TfidfTransformer(smooth_idf=True, use_idf=True)\n",
        "vectorized = tfidf_transformer.fit_transform(count_vectorized)\n",
        "\n",
        "pd.DataFrame(vectorized.toarray(), \n",
        "             index=['sentence '+str(i) for i in range(1, 1+len(corpus))],\n",
        "             columns=vectorizer.get_feature_names())"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>for</th>\n",
              "      <th>great</th>\n",
              "      <th>greatest</th>\n",
              "      <th>lasagna</th>\n",
              "      <th>life</th>\n",
              "      <th>love</th>\n",
              "      <th>loved</th>\n",
              "      <th>the</th>\n",
              "      <th>thing</th>\n",
              "      <th>times</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>sentence 1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.445132</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.564594</td>\n",
              "      <td>0.294628</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.445132</td>\n",
              "      <td>0.445132</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentence 2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.871022</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.227268</td>\n",
              "      <td>0.435511</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentence 3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.539313</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.356966</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.539313</td>\n",
              "      <td>0.539313</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentence 4</th>\n",
              "      <td>0.552805</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.552805</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.288477</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.552805</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 for     great  greatest  ...       the     thing     times\n",
              "sentence 1  0.000000  0.000000  0.445132  ...  0.445132  0.445132  0.000000\n",
              "sentence 2  0.000000  0.871022  0.000000  ...  0.000000  0.000000  0.000000\n",
              "sentence 3  0.000000  0.000000  0.539313  ...  0.539313  0.539313  0.000000\n",
              "sentence 4  0.552805  0.000000  0.000000  ...  0.000000  0.000000  0.552805\n",
              "\n",
              "[4 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjVgMoSfg_KB",
        "colab_type": "text"
      },
      "source": [
        "This is same with:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozNFVPAkbefb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "009871ad-b35a-4408-e2d2-d13df93e4d2c"
      },
      "source": [
        "vectorizer = TfidfVectorizer(analyzer='word', \n",
        "                              token_pattern=r'\\b[a-zA-Z]{3,}\\b',  # Only alphabet, contains at least 3 letters\n",
        "                              ngram_range=(1, 1) # only unigrams\n",
        "                              )  \n",
        "vectorized = vectorizer.fit_transform(corpus)\n",
        "pd.DataFrame(vectorized.toarray(), \n",
        "             index=['sentence '+str(i) for i in range(1, 1+len(corpus))],\n",
        "             columns=vectorizer.get_feature_names())"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>for</th>\n",
              "      <th>great</th>\n",
              "      <th>greatest</th>\n",
              "      <th>lasagna</th>\n",
              "      <th>life</th>\n",
              "      <th>love</th>\n",
              "      <th>loved</th>\n",
              "      <th>the</th>\n",
              "      <th>thing</th>\n",
              "      <th>times</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>sentence 1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.445132</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.564594</td>\n",
              "      <td>0.294628</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.445132</td>\n",
              "      <td>0.445132</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentence 2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.871022</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.227268</td>\n",
              "      <td>0.435511</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentence 3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.539313</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.356966</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.539313</td>\n",
              "      <td>0.539313</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentence 4</th>\n",
              "      <td>0.552805</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.552805</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.288477</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.552805</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 for     great  greatest  ...       the     thing     times\n",
              "sentence 1  0.000000  0.000000  0.445132  ...  0.445132  0.445132  0.000000\n",
              "sentence 2  0.000000  0.871022  0.000000  ...  0.000000  0.000000  0.000000\n",
              "sentence 3  0.000000  0.000000  0.539313  ...  0.539313  0.539313  0.000000\n",
              "sentence 4  0.552805  0.000000  0.000000  ...  0.000000  0.000000  0.552805\n",
              "\n",
              "[4 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSxToP-ChCji",
        "colab_type": "text"
      },
      "source": [
        "After getting the numerical representation of the text data, you are ready to build ML & DL models using it."
      ]
    }
  ]
}